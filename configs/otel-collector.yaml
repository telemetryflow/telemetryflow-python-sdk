# =============================================================================
# OpenTelemetry Collector Configuration
# =============================================================================
#
# TelemetryFlow Python SDK - Community Enterprise Observability Platform (CEOP)
# Copyright (c) 2024-2026 DevOpsCorner Indonesia. All rights reserved.
#
# This config uses STANDARD OpenTelemetry Collector format.
# Use with OTEL Collector Contrib: otelcol-contrib --config otel-collector.yaml
#
# =============================================================================
# OTLP HTTP Endpoints (OCB/OTEL Community - v1 ONLY)
# =============================================================================
#   Standard OpenTelemetry endpoints:
#     POST http://localhost:4318/v1/traces
#     POST http://localhost:4318/v1/metrics
#     POST http://localhost:4318/v1/logs
#
#   gRPC:
#     localhost:4317
#
#   NOTE: v2 endpoints are NOT supported in OCB builds.
#         Use TFO Standalone build for v2 endpoint support.
#
# =============================================================================
# Features demonstrated:
# - Metrics, Logs, Traces collection
# - Exemplars support via spanmetrics connector
# - Service graph generation
# =============================================================================

# =============================================================================
# RECEIVERS - How telemetry data enters the collector
# =============================================================================
receivers:
  # OTLP receiver for OpenTelemetry Protocol (metrics, logs, traces)
  otlp:
    protocols:
      grpc:
        endpoint: "0.0.0.0:4317"
        max_recv_msg_size_mib: 4
        max_concurrent_streams: 100
        read_buffer_size: 524288
        write_buffer_size: 524288
        keepalive:
          server_parameters:
            max_connection_idle: 15s
            max_connection_age: 30s
            max_connection_age_grace: 5s
            time: 10s
            timeout: 5s
      http:
        endpoint: "0.0.0.0:4318"
        cors:
          allowed_origins:
            - "*"
          allowed_headers:
            - "*"
          max_age: 7200

# =============================================================================
# PROCESSORS - How telemetry data is processed
# =============================================================================
processors:
  # Batch processor for efficient data handling
  batch:
    timeout: 200ms
    send_batch_size: 8192
    send_batch_max_size: 0

  # Memory limiter to prevent OOM
  memory_limiter:
    check_interval: 1s
    limit_percentage: 80
    spike_limit_percentage: 25

  # Resource processor for adding attributes
  resource:
    attributes:
      - key: service.namespace
        value: telemetryflow
        action: upsert
      - key: deployment.environment
        value: development
        action: upsert
      - key: telemetryflow.sdk.language
        value: python
        action: upsert

# =============================================================================
# CONNECTORS - Pipeline bridging for Exemplars and derived metrics
# =============================================================================
connectors:
  # Span metrics connector - derives metrics from traces with EXEMPLARS support
  # This enables metrics with trace exemplars for drill-down from metrics to traces
  spanmetrics:
    histogram:
      explicit:
        buckets: [1ms, 5ms, 10ms, 25ms, 50ms, 100ms, 250ms, 500ms, 1s, 2.5s, 5s, 10s]
    dimensions:
      - name: http.method
        default: GET
      - name: http.status_code
      - name: http.route
      - name: rpc.method
      - name: rpc.service
    exemplars:
      enabled: true  # Enable exemplars for metrics-to-traces correlation
    namespace: traces
    metrics_flush_interval: 15s

  # Service graph connector - builds service dependency graphs from traces
  servicegraph:
    latency_histogram_buckets: [1ms, 5ms, 10ms, 25ms, 50ms, 100ms, 250ms, 500ms, 1s, 2.5s, 5s, 10s]
    dimensions:
      - http.method
      - http.status_code
    store:
      ttl: 2s
      max_items: 1000
    cache_loop: 1s
    store_expiration_loop: 2s
    virtual_node_peer_attributes:
      - db.system
      - messaging.system
      - rpc.service

# =============================================================================
# EXPORTERS - Where telemetry data is sent
# =============================================================================
exporters:
  # Debug exporter for development/troubleshooting
  debug:
    verbosity: detailed
    sampling_initial: 5
    sampling_thereafter: 200

  # OTLP exporter to Jaeger (uncomment to enable)
  # otlp/jaeger:
  #   endpoint: jaeger:4317
  #   tls:
  #     insecure: true

  # Prometheus exporter for metrics scraping (with exemplars support)
  prometheus:
    endpoint: "0.0.0.0:8889"
    namespace: telemetryflow
    const_labels:
      collector: tfo-collector
      sdk: python
    send_timestamps: true
    metric_expiration: 5m
    enable_open_metrics: true  # Required for exemplars
    resource_to_telemetry_conversion:
      enabled: true

# =============================================================================
# EXTENSIONS - Additional collector capabilities
# =============================================================================
extensions:
  # Health check extension
  health_check:
    endpoint: "0.0.0.0:13133"

  # zPages extension for debugging
  zpages:
    endpoint: "0.0.0.0:55679"

  # pprof extension for profiling
  pprof:
    endpoint: "0.0.0.0:1777"

# =============================================================================
# SERVICE - Defines active components and pipelines
# =============================================================================
service:
  extensions: [health_check, zpages, pprof]

  pipelines:
    # ==========================================================================
    # Traces pipeline - receives traces, exports to debug and spanmetrics connector
    # ==========================================================================
    traces:
      receivers: [otlp]
      processors: [memory_limiter, batch, resource]
      exporters: [debug, spanmetrics, servicegraph]  # Export to connectors for derived metrics

    # ==========================================================================
    # Metrics pipeline - receives metrics from OTLP
    # ==========================================================================
    metrics:
      receivers: [otlp]
      processors: [memory_limiter, batch, resource]
      exporters: [debug, prometheus]

    # ==========================================================================
    # Metrics from traces pipeline - receives derived metrics from spanmetrics connector
    # These metrics include EXEMPLARS for correlation with traces
    # ==========================================================================
    metrics/spanmetrics:
      receivers: [spanmetrics]
      processors: [memory_limiter, batch]
      exporters: [prometheus]

    # ==========================================================================
    # Metrics from service graph - receives service dependency metrics
    # ==========================================================================
    metrics/servicegraph:
      receivers: [servicegraph]
      processors: [memory_limiter, batch]
      exporters: [prometheus]

    # ==========================================================================
    # Logs pipeline
    # ==========================================================================
    logs:
      receivers: [otlp]
      processors: [memory_limiter, batch, resource]
      exporters: [debug]

  # Internal telemetry configuration
  telemetry:
    logs:
      level: info
      encoding: json

    metrics:
      level: detailed
      readers:
        - pull:
            exporter:
              prometheus:
                host: "0.0.0.0"
                port: 8888
